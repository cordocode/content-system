# Content Automation System - Implementation Plan V2
**Last Updated:** November 12, 2025  
**Status:** Deployment Fixed, Testing Phase

---

## Executive Summary

An intelligent content assistant that manages blog and LinkedIn content production through email communication. Ben sends brain dumps via email with "CONTENT" in the subject line, the system analyzes the input and generates appropriate content (1-5 pieces), sends it back for approval, and publishes on a schedule using a position-based queue system.

**Key Architecture Decisions:**
- Email processing via **Gmail polling (every 5 minutes)** instead of Pub/Sub webhooks
- Blog publishing via **direct Supabase database writes** (no separate API)
- **Shared Supabase database** between content system and company website
- Cron-based scheduling with **CRON_SECRET security**
- Queue system based on **positions (1, 2, 3...)** not dates
- **Pure Node.js serverless functions** (NOT Next.js)

---

## Current Project Status

### âœ… COMPLETED & VERIFIED

#### Infrastructure
- [x] Local development environment set up
- [x] Git repository initialized and pushed to GitHub
- [x] Vercel project connected to GitHub
- [x] Supabase database project created (shared with website)
- [x] Node.js project with all dependencies installed
- [x] **Vercel deployment fixed (removed Next.js, set framework to "Other")**

#### Database
- [x] All content system tables created in Supabase:
  - `content_library` (with pgvector support)
  - `conversation_threads`
  - `content_versions`
  - `assistant_memory`
- [x] Database helper functions (`shift_queue_positions`, `match_content`)
- [x] Indexes created for performance
- [x] Verified connection to existing `blog_posts` table (from website)

#### Authentication & APIs
- [x] Gmail API enabled and OAuth2 configured
- [x] Gmail refresh token obtained and tested
- [x] Google Sheets API enabled
- [x] Service account created and JSON key stored
- [x] Supabase credentials configured
- [x] Anthropic API key configured

#### Testing
- [x] Gmail send/receive tested successfully
- [x] Google Sheets read/write tested (wrote to cell A6 on all 3 tabs)
- [x] Supabase CRUD operations tested
- [x] Environment variables loaded correctly

#### Core Files
- [x] Queue management library (`lib/queue.js`)
- [x] Email utility helper (`lib/email.js`)
- [x] Google Sheets utility (`lib/sheets.js`)
- [x] TypeScript types defined (`types/index.ts`)
- [x] Updated `package.json` with all dependencies (Next.js removed)

### ðŸ”¨ BUILT BUT NOT TESTED

#### API Endpoints
- [ ] `/api/content/generate` - Content generation endpoint
- [ ] `/api/email/poll` - Gmail polling cron (every 5 minutes)
- [ ] `/api/publish/blog` - Blog publishing (direct DB write)
- [ ] `/api/publish/linkedin` - LinkedIn publishing (API call)
- [ ] `/api/assistant/lineup` - Monday morning lineup email

#### Security
- [x] CRON_SECRET environment variable configured
- [x] All cron endpoints secured with auth header check
- [ ] Not tested in production yet

### â³ NOT STARTED

#### LinkedIn Integration
- [ ] LinkedIn API "Share on LinkedIn" product approval (pending)
- [ ] LinkedIn access token generation (waiting for approval)
- [ ] LinkedIn publishing endpoint testing

#### Email Processing
- [ ] Approval parsing logic (revision requests, swapping)
- [ ] Queue management through email commands ("B1 next", "show more")
- [ ] Revision loop implementation

#### Advanced Features
- [ ] Semantic search for past content
- [ ] Vector embeddings generation
- [ ] Style matching based on past content
- [ ] Assistant memory system
- [ ] Proactive content suggestions
- [ ] Google Sheets status tracking integration

---

## System Architecture

### Email Flow (Gmail Polling)

**Decision:** Using Gmail API polling every 5 minutes instead of Google Cloud Pub/Sub
**Reason:** Pub/Sub is unreliable and complex to configure; polling is simple and sufficient

```
Every 5 minutes â†’ `/api/email/poll` cron runs
                  â†“
         Gmail API query: from:ben@corradoco.com subject:CONTENT is:unread
                  â†“
         Process each unread email
                  â†“
         Check if reply to existing thread OR new content request
                  â†“
         Generate content OR handle approval
                  â†“
         Send approval email back to Ben
                  â†“
         Mark email as read
```

**Email Requirements:**
- **From:** ben@corradoco.com (hardcoded filter)
- **Subject:** Must contain "CONTENT" (case insensitive)
- **Body:** Brain dump, story, insight, or approval response

### Content Generation Logic

**CRITICAL:** The system must intelligently determine how many pieces of content to create based on input substance. It does NOT fabricate or stretch content.

**Content Prompt (Final Version):**
```
You are an intelligent content assistant for Ben Corrado, founder of Corrado & Co., 
a Denver-based automation consulting company.

CONTEXT:
- Ben sends you brain dumps, stories, insights, or quick ideas via email
- Your job is to transform these into polished blog posts and LinkedIn content
- You're part of a content automation system that helps Ben maintain consistent output

BEN'S VOICE & EXPERTISE:
- Automation consultant specializing in n8n, Zapier, custom code workflows
- Works with mid-sized companies (20-100 employees)
- Values efficiency, excellence, systematic approaches
- Writes in a professional but approachable tone - technical when needed, 
  accessible when possible, honest and realistic
- Uses real examples from client work
- Focuses on practical, actionable insights

YOUR TASK:
1. ANALYZE the input to determine what content can legitimately be created from it
2. DO NOT fabricate or stretch content too far beyond what the input supports
3. Generate between 1-5 total pieces based on substance:
   - Minimum: 1 LinkedIn post (always possible)
   - Maximum: 2 blog posts + 3 LinkedIn posts

CONTENT GUIDELINES:
- Blog posts: 800-1200 words, deeper dives, technical depth, real examples
- LinkedIn posts: 75-200 words, conversational, single insight or story, actionable

ASSESSMENT CRITERIA:
- Quick tip/hack = 1 LinkedIn post
- Single story/insight = 1 LinkedIn post or 1 blog
- Detailed case study = 1 blog + 1-2 LinkedIn posts
- Multiple insights = 2-3 LinkedIn posts (different angles)
- Major project/learning = 1-2 blogs + 2-3 LinkedIn posts
```

**Output Format:**
```json
{
  "assessment": "Brief explanation of what you decided and why",
  "blog": [
    {
      "title": "...",
      "content": "...",
      "excerpt": "..."
    }
  ],
  "linkedin": [
    { "content": "..." }
  ]
}
```

### Blog Publishing Architecture

**Decision:** Direct database writes to shared `blog_posts` table instead of separate API
**Reason:** Website and content system share the same Supabase database - no need for HTTP overhead

```
Monday 10am cron â†’ `/api/publish/blog`
                    â†“
           Get content at queue position 1
                    â†“
           Generate slug from title
                    â†“
           INSERT directly into `blog_posts` table
                    â†“
           UPDATE `content_library` status to 'posted'
                    â†“
           Shift remaining queue positions up
                    â†“
           Website automatically shows new blog post
```

**Table Relationship:**
- `content_library` table: Content system's staging/queue
- `blog_posts` table: Website's production table (shared)
- When published, content is INSERTED into `blog_posts` and marked as 'posted' in `content_library`

### Queue System

**Key Concept:** Content lives in numbered positions (1, 2, 3...) not scheduled dates. This allows flexible reordering.

**Queue Operations:**
- `addToQueue(contentId, type)` - Adds to end of queue
- `swapWithNext(contentId, type)` - Swaps with next item
- `moveToPosition(contentId, type, position)` - Moves to specific position
- `removeFromQueue(contentId)` - Removes from queue
- `getQueue(type, limit)` - Gets queue contents
- `getQueueHealth()` - Checks if queues are healthy

**Publishing Process:**
1. Cron job runs at scheduled time
2. Pull content at position 1
3. Publish to platform
4. Update status to 'posted'
5. Remove from queue (set position to NULL)
6. Call `shift_queue_positions()` to move everyone up

**Email Commands (Planned):**
- "B1 next" - Swap blog at position 1 with position 2
- "L2 - trim intro" - Request revision on LinkedIn post 2
- "Show more blogs" - Display positions 3-5
- "All approved" - Approve all pieces in lineup

---

## Database Schema (Final)

### Content System Tables

```sql
-- Core content storage with vector embeddings
CREATE TABLE content_library (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    title TEXT,
    content TEXT NOT NULL,
    type VARCHAR(20) CHECK (type IN ('blog', 'linkedin')),
    status VARCHAR(20) DEFAULT 'draft',
    version INTEGER DEFAULT 1,
    posted_date TIMESTAMPTZ,
    queue_position INTEGER, -- Position in queue (NULL if not queued)
    embedding vector(1536), -- OpenAI embeddings (NOT IMPLEMENTED YET)
    tags TEXT[],
    style_notes TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Thread management for email conversations
CREATE TABLE conversation_threads (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    content_id UUID REFERENCES content_library(id),
    email_thread_id TEXT, -- Gmail thread ID
    current_version INTEGER DEFAULT 1,
    status VARCHAR(20),
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Version history for content iterations
CREATE TABLE content_versions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    content_id UUID REFERENCES content_library(id),
    thread_id UUID REFERENCES conversation_threads(id),
    version_number INTEGER,
    content TEXT,
    feedback TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Assistant's long-term memory
CREATE TABLE assistant_memory (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    memory_type VARCHAR(50), -- 'weekly_vision', 'style_preference', etc.
    content JSONB,
    valid_from TIMESTAMPTZ DEFAULT NOW(),
    valid_until TIMESTAMPTZ
);

-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Create indexes
CREATE INDEX ON content_library USING ivfflat (embedding vector_cosine_ops);
CREATE INDEX idx_queue_position ON content_library(type, queue_position) WHERE queue_position IS NOT NULL;

-- Helper function to shift queue positions after publishing
CREATE OR REPLACE FUNCTION shift_queue_positions(
  content_type VARCHAR(20),
  from_position INTEGER
)
RETURNS void
LANGUAGE sql
AS $$
  UPDATE content_library
  SET queue_position = queue_position - 1
  WHERE type = content_type 
  AND queue_position > from_position;
$$;

-- Helper function for semantic search (when embeddings are implemented)
CREATE OR REPLACE FUNCTION match_content(
  query_embedding vector(1536),
  match_threshold float,
  match_count int
)
RETURNS TABLE (
  id uuid,
  title text,
  content text,
  type varchar(20),
  similarity float
)
LANGUAGE sql STABLE
AS $$
  SELECT
    id,
    title,
    content,
    type,
    1 - (embedding <=> query_embedding) as similarity
  FROM content_library
  WHERE 1 - (embedding <=> query_embedding) > match_threshold
  ORDER BY embedding <=> query_embedding
  LIMIT match_count;
$$;
```

### Website Tables (Existing - Reference Only)

```sql
-- Blog posts table (existing on website, used by content system for publishing)
CREATE TABLE blog_posts (
  id uuid DEFAULT gen_random_uuid() PRIMARY KEY,
  created_at timestamptz DEFAULT now() NOT NULL,
  updated_at timestamptz DEFAULT now() NOT NULL,
  title text NOT NULL,
  slug text UNIQUE NOT NULL,
  content text NOT NULL,
  excerpt text,
  published boolean DEFAULT false NOT NULL,
  published_at timestamptz
);
```

---

## Configuration Files

### package.json

**CRITICAL:** Do NOT include Next.js in dependencies. This is a pure Node.js serverless functions project.

```json
{
  "name": "content-system",
  "version": "1.0.0",
  "description": "Content automation system for blog and LinkedIn",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "automation",
    "content",
    "linkedin",
    "blog"
  ],
  "author": "Ben Corrado",
  "license": "ISC",
  "dependencies": {
    "@anthropic-ai/sdk": "^0.27.3",
    "@supabase/supabase-js": "^2.39.0",
    "axios": "^1.13.2",
    "dotenv": "^16.3.1",
    "googleapis": "^129.0.0"
  },
  "devDependencies": {
    "@types/node": "^20.10.0",
    "typescript": "^5.3.0"
  }
}
```

### vercel.json

```json
{
  "functions": {
    "api/**/*.js": {
      "memory": 1024,
      "maxDuration": 30
    }
  },
  "crons": [
    {
      "path": "/api/email/poll",
      "schedule": "*/5 * * * *"
    },
    {
      "path": "/api/publish/blog",
      "schedule": "0 10 * * 1"
    },
    {
      "path": "/api/publish/linkedin",
      "schedule": "0 9 * * 2"
    },
    {
      "path": "/api/publish/linkedin",
      "schedule": "0 9 * * 4"
    },
    {
      "path": "/api/publish/linkedin",
      "schedule": "0 9 * * 6"
    },
    {
      "path": "/api/assistant/lineup",
      "schedule": "0 8 * * 1"
    }
  ]
}
```

---

## Environment Variables

```env
# Supabase (shared with website)
SUPABASE_URL=your-supabase-url
SUPABASE_SERVICE_KEY=your-service-key

# APIs
ANTHROPIC_API_KEY=your-claude-key
LINKEDIN_CLIENT_ID=your-linkedin-client-id
LINKEDIN_CLIENT_SECRET=your-linkedin-client-secret
LINKEDIN_ACCESS_TOKEN=your-linkedin-token

# Google
GOOGLE_SERVICE_ACCOUNT=base64-encoded-json
GOOGLE_SHEET_ID=your-sheet-id

# Email
GMAIL_CLIENT_ID=your-client-id
GMAIL_CLIENT_SECRET=your-client-secret
GMAIL_REFRESH_TOKEN=your-refresh-token
EMAIL_ADDRESS=ben@corradoco.com

# Security
CRON_SECRET=random-secret-string
```

---

## Testing Checklist

### Manual Testing Commands

```bash
# Test health endpoint
curl https://your-project.vercel.app/api/health

# Test Gmail polling (requires CRON_SECRET)
curl -X GET https://your-project.vercel.app/api/email/poll \
  -H "Authorization: Bearer YOUR_CRON_SECRET"

# Test blog publishing (requires CRON_SECRET)
curl -X GET https://your-project.vercel.app/api/publish/blog \
  -H "Authorization: Bearer YOUR_CRON_SECRET"

# Test content generation
curl -X POST https://your-project.vercel.app/api/content/generate \
  -H "Content-Type: application/json" \
  -d '{"input": "Test content generation"}'
```

### Database Verification Queries

```sql
-- Check all content
SELECT * FROM content_library ORDER BY created_at DESC;

-- Check queue status
SELECT type, queue_position, title, status 
FROM content_library 
WHERE queue_position IS NOT NULL 
ORDER BY type, queue_position;

-- Check conversation threads
SELECT * FROM conversation_threads;

-- Check what's been published
SELECT * FROM blog_posts ORDER BY published_at DESC;
```

---

## Known Limitations & Future Considerations

### Current Limitations

1. **No OpenAI Integration Yet**
   - Embeddings generation not implemented
   - Semantic search not functional
   - Will need OPENAI_API_KEY when ready

2. **LinkedIn Pending**
   - Can't test LinkedIn publishing until API approved
   - Access token generation blocked

3. **No Revision Logic**
   - Can approve content
   - Cannot request specific changes yet
   - Version history not being used

4. **No Queue Commands**
   - Can't swap from email yet
   - Can't view deep queue
   - Manual database updates required

5. **Google Sheets Not Connected**
   - Status tracking not live
   - Archive not being populated
   - Training examples not being loaded

### Future Enhancements

1. **Multi-account Support**
   - Currently hardcoded to ben@corradoco.com
   - Could support multiple users/companies

2. **Media Attachments**
   - LinkedIn posts with images
   - Blog posts with featured images
   - Process attachments from emails

3. **Analytics Dashboard**
   - Content performance tracking
   - Queue health monitoring
   - Publishing history

4. **Advanced Scheduling**
   - Specific date scheduling
   - Time zone handling
   - Holiday skipping

5. **Webhook Notifications**
   - Slack notifications
   - Discord updates
   - SMS alerts

---

## Troubleshooting Guide

### Vercel Deployment Fails

**Symptoms:** "Couldn't find any `pages` or `app` directory" error

**Root Cause:** Vercel detecting project as Next.js

**Fix:**
1. Remove Next.js from `package.json` dependencies
2. Delete `package-lock.json`
3. In Vercel dashboard: Settings â†’ Build & Development Settings â†’ Framework Preset â†’ Change to "Other"
4. Redeploy

**Prevention:**
- Never add Next.js, React, or React-DOM to dependencies
- This is a pure Node.js serverless functions project

### Gmail Polling Not Working

**Symptoms:** Emails sent but no response
**Check:**
1. Vercel logs for cron execution
2. Email subject contains "CONTENT"
3. Email from ben@corradoco.com
4. CRON_SECRET set in Vercel
5. Gmail API quota in Google Cloud Console

**Debug:**
```bash
# Check Vercel logs
vercel logs --follow

# Manually trigger polling
curl -X GET https://your-project.vercel.app/api/email/poll \
  -H "Authorization: Bearer $CRON_SECRET"
```

### Content Not Generating

**Symptoms:** Email processed but no content created
**Check:**
1. Anthropic API key valid
2. Supabase connection working
3. Check Vercel logs for errors
4. Verify JSON parsing isn't failing

**Debug:**
```sql
-- Check if content was created
SELECT * FROM content_library ORDER BY created_at DESC LIMIT 5;

-- Check conversation threads
SELECT * FROM conversation_threads ORDER BY created_at DESC LIMIT 5;
```

### Blog Not Publishing

**Symptoms:** Cron runs but blog doesn't appear
**Check:**
1. Content at queue position 1 with status 'approved'
2. Slug generation working (no duplicates)
3. blog_posts table exists and is accessible
4. CRON_SECRET correct

**Debug:**
```sql
-- Check queue
SELECT * FROM content_library 
WHERE type = 'blog' AND queue_position = 1 AND status = 'approved';

-- Check if blog was published
SELECT * FROM blog_posts ORDER BY created_at DESC LIMIT 1;
```

### Cron Jobs Not Running

**Symptoms:** Scheduled jobs never execute
**Check:**
1. Vercel Pro subscription active
2. vercel.json has correct crons configuration
3. CRON_SECRET environment variable set
4. Deployment successful

**Solution:**
- Check Vercel dashboard â†’ Cron Jobs section
- Verify crons are listed and enabled
- Check deployment logs for errors

---

## Success Metrics (Goals)

- **Efficiency:** <5 min from email to draft
- **Quality:** <20% revision rate
- **Queue Health:** Always 1+ blog, 3+ LinkedIn ready
- **Approval Speed:** <2 rounds for approval
- **Publishing:** Zero missed publishing slots
- **Time Saved:** 10+ hours/week on content

---

## Key Contacts & Resources

**Project Owner:** Ben Corrado (ben@corradoco.com)  
**Company:** Corrado & Co. (Denver-based automation consulting)  
**GitHub Repo:** cordocode/content-system  
**Vercel Project:** content-system  
**Supabase Project:** (shared with company website)

**External APIs:**
- Gmail API: https://developers.google.com/gmail/api
- LinkedIn API: https://docs.microsoft.com/en-us/linkedin/
- Anthropic API: https://docs.anthropic.com/
- Google Sheets API: https://developers.google.com/sheets/api

**Important Documentation:**
- Vercel Cron Jobs: https://vercel.com/docs/cron-jobs
- Supabase pgvector: https://supabase.com/docs/guides/ai/vector-columns
- Gmail API Node.js: https://github.com/googleapis/google-api-nodejs-client

---

## Final Notes for Future AI Assistants

1. **Never fabricate content beyond the input** - The intelligent analysis is the core value prop
2. **Always use direct DB writes for blog** - Don't create a separate API
3. **Gmail polling is intentional** - Pub/Sub was tried and rejected
4. **CRON_SECRET is mandatory** - All cron endpoints must check it
5. **Queue positions, not dates** - The system is position-based for flexibility
6. **ben@corradoco.com is hardcoded** - This is by design, not a bug
7. **Service account for Sheets, OAuth for Gmail** - Different auth methods for different APIs
8. **LinkedIn is pending** - Can't test until API approved by LinkedIn
9. **Shared Supabase database** - Content system and website use the same DB
10. **Test locally before deploying** - Use the test scripts to verify everything works
11. **NEVER add Next.js to package.json** - This is a pure Node.js serverless functions project
12. **Vercel framework preset MUST be "Other"** - Not Next.js, not anything else

This system is designed to be Ben's personal content assistant. Keep it focused, intelligent, and reliable. Quality over quantity. Substance over fabrication.

---

**Document Version:** 2.1  
**Last Updated:** November 12, 2025  
**Status:** Deployment fixed, ready for testing phase